{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Resnet18实现手写数字识别\n",
    "从pytorch官方网站上抄袭的\n",
    "文章链接\n",
    "https://blog.csdn.net/weixin_45092662/article/details/115177261\n",
    "![图片信息](picture/20220315213205.png)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from torch.utils import data  # 获取迭代数据\n",
    "from torch.autograd import Variable  # 获取变量\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import mnist  # 获取数据集\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"\n",
    "    3x3 convolution with padding\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=(3, 3),\n",
    "                     stride=(stride, stride),\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class ResBlk(nn.Module):\n",
    "    \"\"\"\n",
    "    resnet block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ch_in, ch_out, stride=1):\n",
    "        \"\"\"\n",
    "         小模块\n",
    "        :param ch_in:输入通道\n",
    "        :param ch_out: 输出通道\n",
    "        \"\"\"\n",
    "        super(ResBlk, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(ch_in, ch_out, kernel_size=(3, 3), stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(ch_out)\n",
    "        self.conv2 = nn.Conv2d(ch_out, ch_out, kernel_size=(3, 3), stride=(1, 1), padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(ch_out)\n",
    "        self.extra = nn.Sequential()\n",
    "        if ch_out != ch_in:\n",
    "            # [b, ch_in, h, w] => [b, ch_out, h, w]\n",
    "            self.extra = nn.Sequential(\n",
    "                nn.Conv2d(ch_in, ch_out, kernel_size=(1, 1), stride=stride),\n",
    "                nn.BatchNorm2d(ch_out)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "\n",
    "        :param x: [batch_size, channel, height, weight]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        # short cut\n",
    "        # extra module:[b, ch_in, h, w] => [b, ch_out, h, w]\n",
    "        # element-wise add:\n",
    "        out = self.extra(x) + out\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(3, 3), padding=0),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        # followed 4 blocks\n",
    "\n",
    "        # [b, 64, h, w] => [b, 128, h, w]\n",
    "        self.blk1 = ResBlk(64, 128, stride=2)\n",
    "\n",
    "        # [b, 128, h, w] => [b, 256, h, w]\n",
    "        self.blk2 = ResBlk(128, 256, stride=2)\n",
    "\n",
    "        # [b, 256, h, w] => [b, 512, h, w]\n",
    "        self.blk3 = ResBlk(256, 512, stride=2)\n",
    "\n",
    "        # [b, 512, h, w] => [b, 512, h, w]\n",
    "        self.blk4 = ResBlk(512, 512, stride=2)\n",
    "\n",
    "        self.outlayer = nn.Linear(512 * 1 * 1, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        print(x)\n",
    "        # [b, 1, h, w] => [b, 64, h, w]\n",
    "        x = F.relu(self.conv1(x))\n",
    "\n",
    "        # [b, 64, h, w] => [b, 512, h, w]\n",
    "        x = self.blk1(x)\n",
    "        x = self.blk2(x)\n",
    "        x = self.blk3(x)\n",
    "        x = self.blk4(x)\n",
    "\n",
    "        # print(x.shape) # [b, 512, 1, 1]\n",
    "        # 意思就是不管之前的特征图尺寸为多少，只要设置为(1,1)，那么最终特征图大小都为(1,1)\n",
    "        # [b, 512, h, w] => [b, 512, 1, 1]\n",
    "        x = F.adaptive_avg_pool2d(x, [1, 1])\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.outlayer(x)\n",
    "\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. 加载数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "path = r\"./model\"\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "\n",
    "def get_dataloader(mode):\n",
    "    \"\"\"\n",
    "    获取数据集加载\n",
    "    :param mode:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #准备数据迭代器\n",
    "    # 这里我已经下载好了，所以是否需要下载写的是false\n",
    "    #准备数据集，其中0.1307，0.3081为MNIST数据的均值和标准差，这样操作能够对其进行标准化\n",
    "    #因为MNIST只有一个通道（黑白图片）,所以元组中只有一个值\n",
    "    dataset = torchvision.datasets.MNIST('../../data/mini', train=mode,\n",
    "                                         download=False,\n",
    "                                         transform=torchvision.transforms.Compose([\n",
    "                                             torchvision.transforms.ToTensor(),\n",
    "                                             torchvision.transforms.Normalize(\n",
    "                                                 (0.1307,), (0.3081,))\n",
    "                                         ]))\n",
    "\n",
    "    return DataLoader(dataset, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(3, 3))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (blk1): ResBlk(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (extra): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (blk2): ResBlk(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (extra): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (blk3): ResBlk(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (extra): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (blk4): ResBlk(\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (extra): Sequential()\n",
      "  )\n",
      "  (outlayer): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18()\n",
    "print(model)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. 进行训练和测试"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的长度 938\n",
      "tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]])\n",
      "训练次数0---0:\t--损失值2.565657138824463\n",
      "tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]])\n",
      "tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]])\n",
      "tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]])\n",
      "tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]])\n",
      "tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]])\n",
      "tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]])\n",
      "tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]])\n",
      "tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
      "\n",
      "\n",
      "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          ...,\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
      "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16120/1055987393.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m     \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     60\u001B[0m     \u001B[0mtest\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_16120/1055987393.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(epoch)\u001B[0m\n\u001B[0;32m     14\u001B[0m         \u001B[1;31m# 使用优化器优化损失\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m         \u001B[0mopt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# 清空上一步残余更新参数值\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m         \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# 误差反向传播，计算参数更新值\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m         \u001B[0mopt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# 将参数更新值施加到net的parmeters上\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mi\u001B[0m \u001B[1;33m%\u001B[0m \u001B[1;36m200\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda\\lib\\site-packages\\torch\\_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    305\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    306\u001B[0m                 inputs=inputs)\n\u001B[1;32m--> 307\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    308\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    309\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    152\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    153\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 154\u001B[1;33m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[0;32m    155\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    156\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def train(epoch):\n",
    "    loss_count = []\n",
    "    # 获取训练集\n",
    "    train_loader = get_dataloader(True)\n",
    "    print(\"训练集的长度\", len(train_loader))\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        # 通道数是1 ,28*28的灰度图,batch_size=64\n",
    "        batch_x = Variable(x)  # torch.Size([batch_size, 1, 28, 28])\n",
    "        batch_y = Variable(y)  # torch.Size([batch_size])\n",
    "        # 获取最后输出\n",
    "        out = model(batch_x)  # torch.Size([batch_size,10])\n",
    "        # 获取损失\n",
    "        loss = loss_func(out, batch_y)\n",
    "        # 使用优化器优化损失\n",
    "        opt.zero_grad()  # 清空上一步残余更新参数值\n",
    "        loss.backward()  # 误差反向传播，计算参数更新值\n",
    "        opt.step()  # 将参数更新值施加到net的parmeters上\n",
    "        if i % 200 == 0:\n",
    "            loss_count.append(loss.item())\n",
    "            print('训练次数{}---{}:\\t--损失值{}'.format(\n",
    "                epoch,\n",
    "                i, loss.item()))\n",
    "            # 保存训练模型，以便下次使用\n",
    "\n",
    "            torch.save(model.state_dict(), r'./model/resnet_model.pkl')\n",
    "    # 打印测试诗句\n",
    "    # print(loss_count)\n",
    "    plt.figure('PyTorch_CNN_的损失值')\n",
    "    plt.plot(range(len(loss_count)), loss_count, label='Loss')\n",
    "    plt.title('PyTorch_CNN_的损失值')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test():\n",
    "    # 获取测试集\n",
    "    accuracy_sum = []\n",
    "    test_loader = get_dataloader(False)\n",
    "    for index, (a, b) in enumerate(test_loader):\n",
    "        test_x = Variable(a)\n",
    "        test_y = Variable(b)\n",
    "        out = model(test_x)\n",
    "        accuracy = torch.max(out, 1)[1].numpy() == test_y.numpy()\n",
    "        accuracy_sum.append(accuracy.mean())\n",
    "        if index % 100 == 0:\n",
    "            print('测试了100批次准确率为:\\t', accuracy.mean())\n",
    "\n",
    "    print('总准确率：\\t', sum(accuracy_sum) / len(accuracy_sum))\n",
    "    # 精确率图\n",
    "    plt.figure('Accuracy')\n",
    "    print(accuracy_sum)\n",
    "    plt.plot(range(len(accuracy_sum)), accuracy_sum, 'o', label='accuracy')\n",
    "    plt.title('Pytorch_CNN_准确率')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for epoch in range(3):\n",
    "    train(epoch)\n",
    "    test()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}