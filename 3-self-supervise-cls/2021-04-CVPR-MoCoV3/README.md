# MocoV3

> [论文](https://arxiv.org/abs/2104.02057)

## 1. 简介

### 1.1 简介

2021年4月5日，FaceBook团队Xinlei Chen, Saining Xie, Kaiming He发表了《An Empirical Study of Training Self-Supervised Vision Transformers》，研究了一个简单的、渐进的但必须知道的基线：**视觉转换器 (ViT) 的自监督学习**。在这项工作中，我们(论文作者)回归基础并研究了几个基本组件对训练自监督 ViT 的影响。我们观察到**不稳定性**是降低准确性的一个主要问题，它可以被表面上好的结果所掩盖。我们发现这些结果确实是部分失败的，当训练更加稳定时，它们可以得到改善。我们在 MoCo v3 和其他几个自监督框架中对 ViT 结果进行了基准测试，并在各个方面进行了消融。我们讨论当前的积极证据以及挑战和悬而未决的问题。我们希望这项工作能为未来的研究提供有用的数据点和经验。







## 2. 网络







## 3. 代码





