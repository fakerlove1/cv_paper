# 第1章 传统语义分割

## 1. 一句话概括网络



### 1.1 模型总结

* 2015-FCN

  FCN是首个端到端，使用了卷积操作，代替的原本的全连接层，保留像素点的空间位置信息，成为了语义分割的开山之作

* 2015-UNet

  UNet使用编解码结构，跳跃连接，弥补了上采样丢失的信息，在医学上使用非常好的网络

* 2016-Deeplabv1

* 2021-SegFormer



| 模型名称    | 版本  | 输入大小 | 参数量 | Flops | FPS  |
| ----------- | ----- | -------- | ------ | ----- | ---- |
| 2015-FCN    | FCN8s |          |        |       |      |
| 2015-Unet   |       |          |        |       |      |
| 2016-SegNet |       |          |        |       |      |
|             |       |          |        |       |      |
|             |       |          |        |       |      |
|             |       |          |        |       |      |
|             |       |          |        |       |      |
|             |       |          |        |       |      |
|             |       |          |        |       |      |



### 1.2 轻量型模型



* 2021-STDC

  STDC提出了使用专门用来分割任务的轻量型backbone；使用Detail Guidance替代BiSeNet中的Spatial分支，保留低层次细节特征的同时有效地减少了网络计算量。



| 模型名称     | 版本      | 输入大小 | 参数量  | Flops  | FPS  |      |
| ------------ | --------- | -------- | ------- | ------ | ---- | ---- |
|              |           |          |         |        |      |      |
|              |           |          |         |        |      |      |
| 2021-STDC    | STDCV1    | 224*224  |         |        |      |      |
|              |           |          |         |        |      |      |
| 2019-BiSeNet | BiSeNetV1 | 224*224  | 13.385M | 2.908G |      |      |
|              |           |          |         |        |      |      |
|              |           |          |         |        |      |      |
|              |           |          |         |        |      |      |
|              |           |          |         |        |      |      |




## 2. 数据集

### 2.1 COCO

| 模型名称 |      |      |
| -------- | ---- | ---- |
|          |      |      |
|          |      |      |
|          |      |      |



### 2.2 Cityscape val

没有使用额外数据

最简版11G

| 模型名称             | 骨干网络   | 参数量 | FLOPS  | FPS  | miou  | 是否使用了数据 |
| -------------------- | ---------- | ------ | ------ | ---- | ----- | -------------- |
| 2015 FCN             | ResNet-101 | 68.6   | 2203.3 | 1.2  | 76.6  |                |
|                      |            |        |        |      |       |                |
|                      |            |        |        |      |       |                |
| DeeplabV3+           | ResNet-101 | 62.7   | 2032.3 | 1.2  | 80.9  |                |
| 2020-OCRNet          | HRNet-W48  | 70.5   | 1296.8 | 4.2  | 81.1  |                |
| 2020 HRNetV2+OCR     |            |        |        |      | 86.3  |                |
| 2021 HRNetV2-OCR+PSA |            |        |        |      | 86.93 |                |
|                      |            |        |        |      |       |                |
| 2021-SETR            | ViT-Large  | 318.3  |        | 0.5  | 82.2  |                |
|                      |            |        |        |      |       |                |
|                      |            |        |        |      |       |                |
|                      |            |        |        |      |       |                |
| 2021-Segformer       | MIT-B4     | 64.1   | 1240.6 | 3.0  | 83.8  |                |
|                      | MIT-B5     | 84.7   | 1447.6 | 2.5  | 84.0  |                |
|                      |            |        |        |      |       |                |
|                      |            |        |        |      |       |                |
|                      |            |        |        |      |       |                |
|                      |            |        |        |      |       |                |
|                      |            |        |        |      |       |                |
|                      |            |        |        |      |       |                |
|                      |            |        |        |      |       |                |



### 2.3 Ade20k



| 模型名称         | 骨干网络   | 参数量 | FLOPS | FPS  | miou | 是否使用了数据 |
| ---------------- | ---------- | ------ | ----- | ---- | ---- | -------------- |
| 2021-Segformer   | MIT-B4     | 64.1   | 95.7  | 15.4 | 51.1 |                |
|                  | MIT-B5     | 84.7   | 183.3 | 9.8  | 51.8 |                |
| 2015-FCN         | ResNet-101 | 68.6   | 275.7 | 14.8 | 41.4 |                |
| DeeplabV3+       | ResNet-101 | 62.7   | 255.1 | 14.1 | 44.1 |                |
|                  |            |        |       |      |      |                |
| 2020-OCRNet      | HRNet-W48  | 70.5   | 164.8 | 17.0 | 45.6 |                |
|                  |            |        |       |      |      |                |
|                  |            |        |       |      |      |                |
| SETR             | ViT-Large  | 318.3  |       |      |      |                |
|                  |            |        |       |      |      |                |
| 2021-ViT-Adapter |            |        |       |      | 60.5 |                |
|                  |            |        |       |      |      |                |
|                  |            |        |       |      |      |                |







### 2.4 COCO-Stuff





### 2.5 cityscape test





### 2.6 Ade20k val





* 第一步，你要知道什么领域有什么问题，你想解决什么领域的什么问题。所以方方面面的论文，感兴趣的领域都多读一读，建议多读一读综述。
* 第二步，确定你想要解决问题的解决方法，可能解决这个问题会用到很多不同的算法，找一个感兴趣的，方法流行的，也就是近几年方法的研究热点。这样的好处是，可参考论文多，研究有价值。这个阶段大多数人论文会看的云里雾里，根本不知道写的是什么，不要慌张，跳过实验部分，只看他用了什么基础方法，意义是什么。
* 第三步，这个时候已经确定这个方法了，去专门的学习这个方法的原理，系统的学习它的方法步骤。
  觉得掌握之后，就在知网下载一些差一点的学校学报的期刊，这种文章多是对方法没有改进，大多是应用一下，这种文章对于论文初级选手太友好了，这个时候你会发现，你看懂了第一篇文章，从头到尾。多看上几篇基本知道这个方法的一个写论文的步骤，实验的结果流程。
* 第四步，开始接触高质量的文章了，国内大多数论文都是方法改进和应用创新，方法改进更能发表高质量的论文。国外的文章改进的很好，我们老师说完完全全创造一个新方法是不太可能的，这都是数学家之类的科学家做的事，我们能改进的效果更好，就很好了。所以，接触一些高质量的中文，有能力多看外文，然后熟悉他们的改进，进行归纳分析，有的论文会结合多种方法，改进的形式和组合太多了。

