# Unet论文翻译

## 摘要

人们普遍认为深度神经网络需要大量的带标签的样本（数千个）进行训练。在本论文中，我们提出了一个网络和训练策略，更有效的利用了数据，以便更有效地使用可用的带标签的样本。我们使用数据扩张的方法(data augmentation)。由两部分组成：一个收缩路径(contracting path)来获取context information以及一个对称的扩张路径(expanding path)用以精确定位。（The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization.）我们发现这个神经网络使用很少的图片就可以进行端对端的训练（end-to-end ）。并且，在ISBI里的电镜下神经元结构的分割挑战中优于之前的方法 (a sliding-window convolutional network)。用这个的网络训练透射电子显微镜图片 (phase contrast and DIC)我们以很大的优势赢得了2015年ISBI的细胞跟踪挑战（ISBI cell tracking challenge）。然后这个神经网络很快。在最新型的GPU上，512x512图像的分割时间不到一秒。 全部的成果和训练好的神经网络可以在(http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net)上获得（基于caffe）。



## 1. 介绍

在前两年里，卷积神经网络在许多视觉识别任务中，超过了其他技术水平，例如文献[7,3]，然而卷积神经网络已经存在了很长一段时间[8]。因为训练集的规模有限，还要考虑的网络的规模，卷积神经网络一直没有受到重视。Krizhevsky等人[7]于在具有100万张训练图像的ImageNet数据集上对具有8层和数百万个参数的大型网络进行了监督训练。从那之后，很多深度网络都完成了训练。
卷积网络的典型利用是用在分类任务上，其中，图像的输出是单个类标签。然而，在许多视觉任务中，特别是在生物医学图像处理中，希望每个像素的输出应该是多个标签（localization, i.e., a class label）。此外，在生物医学任务中，训练成千上万的图像是不可能的。因此，Ciresan等人[1]训练神经网络（a network in a sliding-window），通过提供像素周围的局部区域（patches）作为输入,来预测每个像素的类标签。

首先，这个网络可以局部化（localize）。其次，从补丁（patches）的角度看，训练数据比训练图像的数量要大得多。这个产生的网络赢得了在2012年的ISBI里的 EM segmentation 挑战。

显然，ciresan等人的方法[1]有两个缺点。首先，它很慢，因为网络必须为每个补丁单独运行，有许多冗余重复的补丁（patches）。其次，localization accuracy和the use of context之间不能全都兼顾。大的补丁（ Larger patches）需要更多的最大池（ max-pooling）层，从而降低局部的准确性。虽然小补丁只能使网络只看到很少的context。最近的方法[11,4]提出了一个考虑到多层特征的分类器输出。使Good localization和 the use of context同时兼顾有了可能。

在本文中，我们建立在一个更好的架构上，它叫“全卷积网络”（fully convolutional network）[9]。我们修改和扩展了这个架构，使其能够处理很少的训练图像就能产生更精确的分割。如下图。

![](https://resource-joker.oss-cn-beijing.aliyuncs.com/picture/2019042317550716.png)

> U-net体系结构(例如32x32像素的最低分辨率)。每个蓝色框对应一个多通道特征映射。通道的数量表示在框的顶部。x-y大小设置在盒子的左下角.白色框表示复制的功能地图。箭头表示不同的操作。



文献[9]主要想法是用连接层（successive layers）来补充普通的神经网络，其中池操作（ pooling operators）被upsampling 操作代替。因此，这些层提高了输出的分辨率（these layers increase the resolution of the output）。为了使用局部的信息（localize），将收缩路径中的高分辨率特征作为上层的输出 （upsampled output）。（In order to localize, high resolution features from the contracting path are combined with the upsampled output）连续卷积层能根据这些信息学习综合，做出更精确的输出。

我们架构中的一个重要修改是，在上采样部分，我们也有大量的特征通道(feature channels)，这使得网络能够将context information传播到更高分辨率的层（higher resolution layers）结果是，扩张路径基本对称于收缩路径，形成了一个U型的结构。这个网络不存在任何全连接层(fully connected layers)，并且，只使用每个卷积的有效部分。例如，分割图(segmentation map)只包含这样一些像素点，这些像素点的完整的context 都出现在输入图像中。该方法允许通过overlap-tile方法对任意大的图像进行无缝分割(见下图)

![](https://resource-joker.oss-cn-beijing.aliyuncs.com/picture/20190425154105930.png)

> overlap-tile方法用于对任意大图像进行无缝分割(这里是对em堆栈中神经元结构的分割)。预测黄色区域的分割，需要输入蓝色区域内的图像数据。缺失的输入数据是通过镜像法（mirroring）推算得到的。



  为了预测边框的像素，我们采用镜像输入图像的方式补全缺失的内容（context）。这种的拼接策略对于将网络应用于大型图像是很重要的，因为否则分辨率将受到GPU内存的限制。

  对于我们的任务，可用的训练数据非常少，we use excessive data augmentation by applying elastic deformations to the available training images.（我们通过对可用的训练图像施加弹性变形来使用过度的数据增强。）。这使得网络去学习这些变形的不变性（invariance to such deformations），而不需要在带注释的图像语料库中查看这些转换。这是非常重要的在生物医学分割中，因为形变曾经是组织中最常见的变异，可以有效地模拟真实的变形。Dosovitskiy et al. [2] 在无监督特征学习的范围内表明了数据增强对学习不变性的价值。

  另一个挑战在许多细胞分割任务中是分离同一类的touching objects 看图3。为此，我们建议使用 weighted loss,（加权损耗）。这种情况下，分离背景标签在touching cells之间包含一个很大的权重在损失函数中。

  所得结果网络适用于各种生物医学分割问题。在这篇论文中，我们展示了在EM stacks(EM堆栈)(ISBI 2012开始了一项正在进行的比赛)中神经元结构的分割结果。所得结果超过了Ciresan et al. [1].该文的网络。此外，我们还展示了来自ISBI细胞跟踪挑战赛2015的光镜图像中的细胞分割结果。在这两个最具挑战性的2D透射光数据集上，我们以很大的优势获胜。

## 2. 网络结构

网络体系结构如图1所示。它由contracting path (left side) and an expansive path(收缩路径(左侧)和扩展路径(右侧)组成)。收缩路径遵循卷积网络的典型结构。它包括重复应用两个3x3的卷积(无填充卷积)，每个卷积后面有一个整流线性单元(ReLU)和一个2x2的最大池操作(步幅为2)，用于downsampling(下行采样)。在每个下采样步骤中，我们将特征通道的数量增加一倍。expansive path的每一步都包括特征图的上采样，然后是将特征通道数量减半的2x2卷积（“上卷积”），与来自收缩路径的相应裁剪特征图的连接，以及两个3x3卷积，每个卷积后面跟着一个relu。在最后一层使用1x1卷积来映射每个64组件特征向量到所需的类数。该网络总共23个卷积层。

为了允许输出分割图的无缝平铺(见图2)。选择输入平铺大小是很重要的，这样所有2x2max-pooling操作都应用于具有均匀x和y大小的图层上。



## 3. 训练

使用caffe【6】的随机梯度下降算法对输入图像和他们相应的分割图进行训练。由于未填充卷积，输出图像比输入图像小一个恒定的边框宽度。为了最小化开销并最大限度的利用GPU内存，我们赞成大的输入贴图而不是大的批处理大小，从而将批处理减少到单个图像。因此，我们使用一个高动量(0.99)，这样大量之前看到的训练样本决定了当前优化步骤中的更新。

energy函数被计算是通过最终特征图上的逐像素 soft-max结合交叉熵损失函数。soft-max被定义为pk(x),$p_k(x)=exp(a_k(x))/(\sum_{k^\prime=1}^K exp(a_{k^\prime}(x))$ ,$a_k(x)$表示在像素位置x∈Ω的特征通道k中激活。Ω⊂Z2。k为类别的数量，pk(x)是近似的最大值函数。对于具有最大激活 ak(x) 的 k，pk(x) ≈ 1，对于所有其他 k，pk(x) ≈ 0。
$$
E=\sum_{x\in \Omega }w(x)log(p_{l(x)}(x))
$$
交叉熵在pl(x)(x)偏离1的每个位置惩罚

![](https://resource-joker.oss-cn-beijing.aliyuncs.com/picture/6ae382de71ee44b9b8b3fb12282b1711.png)

> （a）原始图像
> （b）标注图像实况分割 不同的颜色表示HeLa细胞的不同情况
> （c）生成分割蒙版（白色：前景，黑色：背景）
> （d）以像素为单位的权重映射，迫使网络学习边界像素



其中$l:\Omega\to \{1,\cdots,K\}$为每个像素的真标签，$w:\Omega\to R$为我们引入的权重图，在训练中赋予某些像素更多的重要性。

我们预先计算每个ground truth  segmentation的权值图来补偿训练数据集中某类像素的不同频率，并强制网络学习我们在接触cell之间引入的小的分离边界(如图3c和d)。

使用形态运算计算分离边界。然后将权重映射计算为
$$
w(x)=w_c(x)_+w_0\cdot exp(-\frac{(d_1(x)+d_2(x))^2}{2\sigma^2})
$$
其中$w_c:\Omega\to R$为平衡类频率的权重映射，$d_1:\Omega\to R$为到最近的cell边界的距离，$d_2:\Omega\to R$为到第二个最近cell边界的距离。在实验中，我们设置了$w_0=10,\sigma\approx 5$像素

在具有多个卷积层和不同网络路径的深度网络中，对权值进行良好的初始化是非常重要的。否则，网络的某些部分可能会产生过多的激活，而其他部分则不会。理想情况下，初始权值应调整，使网络中的每个特征映射具有近似单位方差。对于采用我们的结构(交替卷积和ReLU层)的网络，这可以通过从标准偏差为$\sqrt{\frac{2}{N}}$的高斯分布中绘制初始权值来实现，其中N表示一个神经元[5]的传入节点数。

例如，对于前一层的3x3卷积和64个特征通道$N=9\cdot 64=576$

### 3.1 数据扩充

当只有很少的训练样本可用时，要想尽可能的让网络获得不变性和鲁棒性，数据增加是很重要的。在显微图像的情况下，我们主要需要平移和旋转不变性以及对变形和灰度值变化的鲁棒性。将训练样本进行随机弹性变形似乎是训练具有很少注释图像的分割网络的关键概念。我们使用随机位移矢量在粗糙的3x3的网格上产生平滑的形变。位移是从具有 10 个像素标准偏差的高斯分布中采样的。然后使用双三次插值计算每个像素位移。 收缩路径末端使用 Drop-out 层执行进一步的隐式数据增强。（implicit data augmentation）.






## 4. 实验

我们演示了u-net在三个不同的细分任务中的应用。第一个任务是在电子显微镜记录中分割神经元结构。图2显示了数据集的一个例子和我们获得的分割。我们提供完整的结果作为补充资料。该数据集由新兴市场细分挑战[14]提供，该挑战始于ISBI  2012年，目前仍在接受新的贡献。训练数据是一组30张(512x512像素)的果蝇一龄幼虫腹侧神经索(VNC)的连续切片透射电子显微镜图像。每个图像都有相应的细胞(白色)和膜(黑色)的完全注释的地面真相分割图。测试集是公开的，但是它的分割图是保密的。评估可以通过将预测的膜概率图发送给组织者来获得。评估是通过将地图划分为10个不同的等级，并计算“扭曲误差”、“兰德误差”和“像素误差”[14]来完成的。



u-net(平均超过7个旋转版本的输入数据)在没有任何进一步的预处理或后处理的情况下实现了0.0003529的翘曲误差(新的最佳分数，见表1)和0.0382的随机误差。

这明显优于Ciresan et al.[1]的滑动窗口卷积网络结果，其最佳提交的翘曲误差为0.000420，兰德误差为0.0504。

![image-20220408150749263](https://resource-joker.oss-cn-beijing.aliyuncs.com/picture/image-20220408150749263.png)

![image-20220408150807478](https://resource-joker.oss-cn-beijing.aliyuncs.com/picture/image-20220408150807478.png)

在rand误差方面，只有更好的表现该数据集上的算法使用了高度特定于数据集的后处理方法1，该方法应用于Ciresan等人的概率图。

我们还将u-net应用到光镜图像的细胞分割任务中。这个分割任务是2014年和2015年ISBI cell tracking  challenge的一部分[10,13]。第一个数据集“PhC-U373”2包含聚丙烯酰亚胺底物上的胶质母细胞瘤-星形细胞瘤U373细胞，通过相差显微镜记录(见图4a,b和附录材料)。它包含35个部分标注的训练图像。这里我们实现平均借据(“十字路口在联盟”)的92%,这是明显比第二个最好的算法为83%(见表2)。第二个数据集“DIC-HeLa”3海拉细胞在平板玻璃(DIC)微分干涉对比显微镜记录的(参见图3,图4  c, d和增刊。材料)。它包含20个部分标注的训练图像。这里我们获得了平均77.5%的IOU，明显优于第二好的46%的算法。



## 5. 结论

u-net架构在非常不同的生物医学细分应用上取得了非常好的性能。由于采用了弹性变形的数据增强技术，它只需要很少的注释图像，具有非常合理的在NVidia Titan GPU (6gb)上仅10小时的训练时间。我们提供全面的基于Caffe[6]的实现和训练有素的网络4。我们相信，u-net架构可以很容易地应用于更多的任务